{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "83fb1cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy  version -  1.20.3\n",
      "pandas version -  1.3.4\n",
      "sklearn version -  0.24.2\n"
     ]
    }
   ],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "print('numpy  version - ' , np.__version__) \n",
    "print('pandas version - ' , pd.__version__) \n",
    "\n",
    "\n",
    "# ml\n",
    "import sklearn\n",
    "from   sklearn.datasets import load_iris, load_breast_cancer\n",
    "\n",
    "print('sklearn version - ' , sklearn.__version__)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold , StratifiedKFold , cross_val_score, cross_validate, GridSearchCV \n",
    "from sklearn.tree            import DecisionTreeClassifier\n",
    "from sklearn.ensemble        import RandomForestClassifier\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "\n",
    "from sklearn.metrics         import accuracy_score, recall_score, precision_score, f1_score, make_scorer, precision_recall_curve\n",
    "from sklearn.preprocessing   import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572823c6",
   "metadata": {},
   "source": [
    "## 분류모델의 성능평가\n",
    "- 정확도 : 실 데이터와 예측 데이터가 얼마나 같은지를 판단하는 지표\n",
    "- 문제점? - 이진분류의 경우 모델의 성능을 왜곡할 수 있다.\n",
    "- 왜 : 데이터의 불균형\n",
    "- 해결책 : F1 Score(Percision, Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d642d6c",
   "metadata": {},
   "source": [
    "- 정밀도(Percision) : TP / (FP + TP)\n",
    "- 상대적으로 정밀도가 더 중요한 지표인 경우의 모델? 스팸메일\n",
    "- 재현율(Recall) : TP / (TP + FN)\n",
    "- 상대적으로 재현율이 더 중요한 지표인 경우의 모델? 의학(암진단), 금융(사기판별)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65df30e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_frm = pd.read_csv('./dataset/titanic_train.csv')\n",
    "titanic_frm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4334f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_frm[\"Survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26332b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. target, feature로 데이터 분리\n"
     ]
    }
   ],
   "source": [
    "print('2. target, feature로 데이터 분리')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9595a632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target type : <class 'pandas.core.series.Series'>\n",
      "feature type : <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "titanic_target = titanic_frm['Survived']\n",
    "titanic_feature = titanic_frm.drop(['Survived'], axis=1)\n",
    "\n",
    "print('target type :', type(titanic_target))\n",
    "print('feature type :', type(titanic_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31090ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('3. 전처리 요구사항 :')\n",
    "print('불필요한 피처 제거 : PassengerID, Name, Ticket')\n",
    "print('결측값 처리 : age는 평균, cabin은 N, Embarked 는 N')\n",
    "print('레이블 인코딩 : cabin, embarked')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf0a57d",
   "metadata": {},
   "source": [
    "## 실습1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e8850af",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['PassengerId'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4604/2948804687.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtitanic_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtitanic_feature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PassengerId'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtitanic_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtitanic_feature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtitanic_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtitanic_feature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Ticket'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtitanic_feature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4904\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4905\u001b[0m         \"\"\"\n\u001b[1;32m-> 4906\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4907\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4908\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4148\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4149\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4150\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4152\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4184\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4185\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6015\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6017\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6019\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['PassengerId'] not found in axis\""
     ]
    }
   ],
   "source": [
    "titanic_feature = titanic_feature.drop(['PassengerId'], axis=1)\n",
    "titanic_feature = titanic_feature.drop(['Name'], axis=1)\n",
    "titanic_feature = titanic_feature.drop(['Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70951dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch     Fare Cabin Embarked\n",
       "0       3    male  22.0      1      0   7.2500   NaN        S\n",
       "1       1  female  38.0      1      0  71.2833   C85        C\n",
       "2       3  female  26.0      0      0   7.9250   NaN        S\n",
       "3       1  female  35.0      1      0  53.1000  C123        S\n",
       "4       3    male  35.0      0      0   8.0500   NaN        S"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "482c217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_feature['Age'].fillna(np.round(np.mean(titanic_feature['Age'])), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5697a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_feature['Cabin'].fillna('N', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84dc0550",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_feature['Embarked'].fillna('N', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07809e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N              687\n",
       "C23 C25 C27      4\n",
       "G6               4\n",
       "B96 B98          4\n",
       "C22 C26          3\n",
       "              ... \n",
       "E34              1\n",
       "C7               1\n",
       "C54              1\n",
       "E36              1\n",
       "C148             1\n",
       "Name: Cabin, Length: 148, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_feature['Cabin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab341e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_cabin(row):\n",
    "    if row == 'N':\n",
    "        return 'N'\n",
    "    else:\n",
    "        return row[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d2cbc57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin_masked = titanic_feature['Cabin'].apply(mask_cabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d40d0991",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_feature.drop(['Cabin'],axis=1, inplace=True)\n",
    "titanic_feature['mask_cabin']=cabin_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1fab86b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>mask_cabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass     Sex   Age  SibSp  Parch     Fare Embarked mask_cabin\n",
       "0         3    male  22.0      1      0   7.2500        S          N\n",
       "1         1  female  38.0      1      0  71.2833        C          C\n",
       "2         3  female  26.0      0      0   7.9250        S          N\n",
       "3         1  female  35.0      1      0  53.1000        S          C\n",
       "4         3    male  35.0      0      0   8.0500        S          N\n",
       "..      ...     ...   ...    ...    ...      ...      ...        ...\n",
       "886       2    male  27.0      0      0  13.0000        S          N\n",
       "887       1  female  19.0      0      0  30.0000        S          B\n",
       "888       3  female  30.0      1      2  23.4500        S          N\n",
       "889       1    male  26.0      0      0  30.0000        C          C\n",
       "890       3    male  32.0      0      0   7.7500        Q          N\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9f75f712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_items_Sex</th>\n",
       "      <th>label_items_mask_cabin</th>\n",
       "      <th>label_items_Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>male</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>female</td>\n",
       "      <td>B</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>female</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>male</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>male</td>\n",
       "      <td>N</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label_items_Sex label_items_mask_cabin label_items_Embarked\n",
       "0              male                      N                    S\n",
       "1            female                      C                    C\n",
       "2            female                      N                    S\n",
       "3            female                      C                    S\n",
       "4              male                      N                    S\n",
       "..              ...                    ...                  ...\n",
       "886            male                      N                    S\n",
       "887          female                      B                    S\n",
       "888          female                      N                    S\n",
       "889            male                      C                    C\n",
       "890            male                      N                    Q\n",
       "\n",
       "[891 rows x 3 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_frm = pd.DataFrame({\n",
    "    'label_items_Sex' : titanic_feature['Sex'],\n",
    "    'label_items_mask_cabin' : titanic_feature['mask_cabin'],\n",
    "    'label_items_Embarked' : titanic_feature['Embarked']\n",
    "})\n",
    "encoder_frm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "51a50a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_items_Sex_female</th>\n",
       "      <th>label_items_Sex_male</th>\n",
       "      <th>label_items_mask_cabin_A</th>\n",
       "      <th>label_items_mask_cabin_B</th>\n",
       "      <th>label_items_mask_cabin_C</th>\n",
       "      <th>label_items_mask_cabin_D</th>\n",
       "      <th>label_items_mask_cabin_E</th>\n",
       "      <th>label_items_mask_cabin_F</th>\n",
       "      <th>label_items_mask_cabin_G</th>\n",
       "      <th>label_items_mask_cabin_N</th>\n",
       "      <th>label_items_mask_cabin_T</th>\n",
       "      <th>label_items_Embarked_C</th>\n",
       "      <th>label_items_Embarked_N</th>\n",
       "      <th>label_items_Embarked_Q</th>\n",
       "      <th>label_items_Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label_items_Sex_female  label_items_Sex_male  label_items_mask_cabin_A  \\\n",
       "0                         0                     1                         0   \n",
       "1                         1                     0                         0   \n",
       "2                         1                     0                         0   \n",
       "3                         1                     0                         0   \n",
       "4                         0                     1                         0   \n",
       "..                      ...                   ...                       ...   \n",
       "886                       0                     1                         0   \n",
       "887                       1                     0                         0   \n",
       "888                       1                     0                         0   \n",
       "889                       0                     1                         0   \n",
       "890                       0                     1                         0   \n",
       "\n",
       "     label_items_mask_cabin_B  label_items_mask_cabin_C  \\\n",
       "0                           0                         0   \n",
       "1                           0                         1   \n",
       "2                           0                         0   \n",
       "3                           0                         1   \n",
       "4                           0                         0   \n",
       "..                        ...                       ...   \n",
       "886                         0                         0   \n",
       "887                         1                         0   \n",
       "888                         0                         0   \n",
       "889                         0                         1   \n",
       "890                         0                         0   \n",
       "\n",
       "     label_items_mask_cabin_D  label_items_mask_cabin_E  \\\n",
       "0                           0                         0   \n",
       "1                           0                         0   \n",
       "2                           0                         0   \n",
       "3                           0                         0   \n",
       "4                           0                         0   \n",
       "..                        ...                       ...   \n",
       "886                         0                         0   \n",
       "887                         0                         0   \n",
       "888                         0                         0   \n",
       "889                         0                         0   \n",
       "890                         0                         0   \n",
       "\n",
       "     label_items_mask_cabin_F  label_items_mask_cabin_G  \\\n",
       "0                           0                         0   \n",
       "1                           0                         0   \n",
       "2                           0                         0   \n",
       "3                           0                         0   \n",
       "4                           0                         0   \n",
       "..                        ...                       ...   \n",
       "886                         0                         0   \n",
       "887                         0                         0   \n",
       "888                         0                         0   \n",
       "889                         0                         0   \n",
       "890                         0                         0   \n",
       "\n",
       "     label_items_mask_cabin_N  label_items_mask_cabin_T  \\\n",
       "0                           1                         0   \n",
       "1                           0                         0   \n",
       "2                           1                         0   \n",
       "3                           0                         0   \n",
       "4                           1                         0   \n",
       "..                        ...                       ...   \n",
       "886                         1                         0   \n",
       "887                         0                         0   \n",
       "888                         1                         0   \n",
       "889                         0                         0   \n",
       "890                         1                         0   \n",
       "\n",
       "     label_items_Embarked_C  label_items_Embarked_N  label_items_Embarked_Q  \\\n",
       "0                         0                       0                       0   \n",
       "1                         1                       0                       0   \n",
       "2                         0                       0                       0   \n",
       "3                         0                       0                       0   \n",
       "4                         0                       0                       0   \n",
       "..                      ...                     ...                     ...   \n",
       "886                       0                       0                       0   \n",
       "887                       0                       0                       0   \n",
       "888                       0                       0                       0   \n",
       "889                       1                       0                       0   \n",
       "890                       0                       0                       1   \n",
       "\n",
       "     label_items_Embarked_S  \n",
       "0                         1  \n",
       "1                         0  \n",
       "2                         1  \n",
       "3                         1  \n",
       "4                         1  \n",
       "..                      ...  \n",
       "886                       1  \n",
       "887                       1  \n",
       "888                       1  \n",
       "889                       0  \n",
       "890                       0  \n",
       "\n",
       "[891 rows x 15 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_frm = pd.get_dummies(encoder_frm)\n",
    "labeled_frm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4628916a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labeled_frm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a6b1242f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_feature_droped = titanic_feature.iloc[:,[0,2,3,4,5]]\n",
    "type(titanic_feature_droped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cb6ae637",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_concat = pd.concat([titanic_feature_droped,labeled_frm], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1cb12b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>label_items_Sex_female</th>\n",
       "      <th>label_items_Sex_male</th>\n",
       "      <th>label_items_mask_cabin_A</th>\n",
       "      <th>label_items_mask_cabin_B</th>\n",
       "      <th>label_items_mask_cabin_C</th>\n",
       "      <th>label_items_mask_cabin_D</th>\n",
       "      <th>label_items_mask_cabin_E</th>\n",
       "      <th>label_items_mask_cabin_F</th>\n",
       "      <th>label_items_mask_cabin_G</th>\n",
       "      <th>label_items_mask_cabin_N</th>\n",
       "      <th>label_items_mask_cabin_T</th>\n",
       "      <th>label_items_Embarked_C</th>\n",
       "      <th>label_items_Embarked_N</th>\n",
       "      <th>label_items_Embarked_Q</th>\n",
       "      <th>label_items_Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass   Age  SibSp  Parch     Fare  label_items_Sex_female  \\\n",
       "0         3  22.0      1      0   7.2500                       0   \n",
       "1         1  38.0      1      0  71.2833                       1   \n",
       "2         3  26.0      0      0   7.9250                       1   \n",
       "3         1  35.0      1      0  53.1000                       1   \n",
       "4         3  35.0      0      0   8.0500                       0   \n",
       "..      ...   ...    ...    ...      ...                     ...   \n",
       "886       2  27.0      0      0  13.0000                       0   \n",
       "887       1  19.0      0      0  30.0000                       1   \n",
       "888       3  30.0      1      2  23.4500                       1   \n",
       "889       1  26.0      0      0  30.0000                       0   \n",
       "890       3  32.0      0      0   7.7500                       0   \n",
       "\n",
       "     label_items_Sex_male  label_items_mask_cabin_A  label_items_mask_cabin_B  \\\n",
       "0                       1                         0                         0   \n",
       "1                       0                         0                         0   \n",
       "2                       0                         0                         0   \n",
       "3                       0                         0                         0   \n",
       "4                       1                         0                         0   \n",
       "..                    ...                       ...                       ...   \n",
       "886                     1                         0                         0   \n",
       "887                     0                         0                         1   \n",
       "888                     0                         0                         0   \n",
       "889                     1                         0                         0   \n",
       "890                     1                         0                         0   \n",
       "\n",
       "     label_items_mask_cabin_C  label_items_mask_cabin_D  \\\n",
       "0                           0                         0   \n",
       "1                           1                         0   \n",
       "2                           0                         0   \n",
       "3                           1                         0   \n",
       "4                           0                         0   \n",
       "..                        ...                       ...   \n",
       "886                         0                         0   \n",
       "887                         0                         0   \n",
       "888                         0                         0   \n",
       "889                         1                         0   \n",
       "890                         0                         0   \n",
       "\n",
       "     label_items_mask_cabin_E  label_items_mask_cabin_F  \\\n",
       "0                           0                         0   \n",
       "1                           0                         0   \n",
       "2                           0                         0   \n",
       "3                           0                         0   \n",
       "4                           0                         0   \n",
       "..                        ...                       ...   \n",
       "886                         0                         0   \n",
       "887                         0                         0   \n",
       "888                         0                         0   \n",
       "889                         0                         0   \n",
       "890                         0                         0   \n",
       "\n",
       "     label_items_mask_cabin_G  label_items_mask_cabin_N  \\\n",
       "0                           0                         1   \n",
       "1                           0                         0   \n",
       "2                           0                         1   \n",
       "3                           0                         0   \n",
       "4                           0                         1   \n",
       "..                        ...                       ...   \n",
       "886                         0                         1   \n",
       "887                         0                         0   \n",
       "888                         0                         1   \n",
       "889                         0                         0   \n",
       "890                         0                         1   \n",
       "\n",
       "     label_items_mask_cabin_T  label_items_Embarked_C  label_items_Embarked_N  \\\n",
       "0                           0                       0                       0   \n",
       "1                           0                       1                       0   \n",
       "2                           0                       0                       0   \n",
       "3                           0                       0                       0   \n",
       "4                           0                       0                       0   \n",
       "..                        ...                     ...                     ...   \n",
       "886                         0                       0                       0   \n",
       "887                         0                       0                       0   \n",
       "888                         0                       0                       0   \n",
       "889                         0                       1                       0   \n",
       "890                         0                       0                       0   \n",
       "\n",
       "     label_items_Embarked_Q  label_items_Embarked_S  \n",
       "0                         0                       1  \n",
       "1                         0                       0  \n",
       "2                         0                       1  \n",
       "3                         0                       1  \n",
       "4                         0                       1  \n",
       "..                      ...                     ...  \n",
       "886                       0                       1  \n",
       "887                       0                       1  \n",
       "888                       0                       1  \n",
       "889                       0                       0  \n",
       "890                       1                       0  \n",
       "\n",
       "[891 rows x 20 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3a941131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import missingno as msno\n",
    "msno.matrix(titanic_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2c2eec2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습과 테스트 분리 :\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('학습과 테스트 분리 :')\n",
    "print()\n",
    "X_train, X_test, y_train, y_test = train_test_split(titanic_concat,\n",
    "                                                    titanic_target,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ff2a594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape , y_train.shape, y_test.shape\n",
    "\n",
    "def metrics_eval(target, prediction) :\n",
    "    print('accuracy :', accuracy_score(target, prediction))\n",
    "    print('recall :', recall_score(target, prediction))\n",
    "    print('precistion :', precision_score(target, prediction))\n",
    "    print('f1 score :', f1_score(target, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9ba9223a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_y_pred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c17bc758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression :\n",
      "\n",
      "accuracy : 0.7723880597014925\n",
      "recall : 0.6407766990291263\n",
      "precistion : 0.7333333333333333\n",
      "f1 score : 0.6839378238341969\n"
     ]
    }
   ],
   "source": [
    "print('LogisticRegression :')\n",
    "print()\n",
    "metrics_eval(y_test, dt_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f7cfef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_y_pred = dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "df90c939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecistionTreeClassifier :\n",
      "\n",
      "accuracy : 0.7388059701492538\n",
      "recall : 0.6504854368932039\n",
      "precistion : 0.6633663366336634\n",
      "f1 score : 0.6568627450980392\n"
     ]
    }
   ],
   "source": [
    "print('DecistionTreeClassifier :')\n",
    "print()\n",
    "metrics_eval(y_test, dt_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9abd6217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차검증 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['fit_time', 'score_time', 'test_accuracy', 'test_recall', 'test_precistion', 'test_f1'])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('교차검증 :')\n",
    "fold = KFold(n_splits=20)\n",
    "scoring = {\n",
    "    'accuracy' : make_scorer(accuracy_score),\n",
    "    'recall' : make_scorer(recall_score),\n",
    "    'precistion' : make_scorer(precision_score),\n",
    "    'f1' : make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "result = cross_validate(lr_model, X_train, y_train,\n",
    "                        cv = fold,\n",
    "                        scoring=scoring)\n",
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cd57e923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.816985887096774"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['test_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54cfe27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03b2628b",
   "metadata": {},
   "source": [
    "## 실습2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6012cb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "680989f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유방암 관련 데이터 : 정확도, 재현율(실제 P를 N으로 예측하면 안되기 때문에)\n",
      "재현율은 실제 양성을 양성으로 예측한 비율이 높아야 성능이 좋은 모델\n"
     ]
    }
   ],
   "source": [
    "print('유방암 관련 데이터 : 정확도, 재현율(실제 P를 N으로 예측하면 안되기 때문에)')\n",
    "print('재현율은 실제 양성을 양성으로 예측한 비율이 높아야 성능이 좋은 모델')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996216ee",
   "metadata": {},
   "source": [
    "- 1. 데이터 프레임 생성(feature, target) 포함\n",
    "- 2. target에 대한 균형 여부 확인\n",
    "- 3. 데이터 세트 분리\n",
    "- 4. RandomForestClassifier\n",
    "- 5. 평가지표 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "54ba1981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d3ba2633",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_frm = pd.DataFrame(data = cancer.data,\n",
    "                          columns = cancer.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "27451e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_frm['target'] = cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c4c436",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_frm['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9f745872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>0.07613</td>\n",
       "      <td>...</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.05742</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.07451</td>\n",
       "      <td>...</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.07389</td>\n",
       "      <td>...</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.08243</td>\n",
       "      <td>...</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "5        12.45         15.70           82.57      477.1          0.12780   \n",
       "6        18.25         19.98          119.60     1040.0          0.09463   \n",
       "7        13.71         20.83           90.20      577.9          0.11890   \n",
       "8        13.00         21.82           87.50      519.8          0.12730   \n",
       "9        12.46         24.04           83.97      475.9          0.11860   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760         0.30010              0.14710         0.2419   \n",
       "1           0.07864         0.08690              0.07017         0.1812   \n",
       "2           0.15990         0.19740              0.12790         0.2069   \n",
       "3           0.28390         0.24140              0.10520         0.2597   \n",
       "4           0.13280         0.19800              0.10430         0.1809   \n",
       "5           0.17000         0.15780              0.08089         0.2087   \n",
       "6           0.10900         0.11270              0.07400         0.1794   \n",
       "7           0.16450         0.09366              0.05985         0.2196   \n",
       "8           0.19320         0.18590              0.09353         0.2350   \n",
       "9           0.23960         0.22730              0.08543         0.2030   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "5                 0.07613  ...          23.75           103.40       741.6   \n",
       "6                 0.05742  ...          27.66           153.20      1606.0   \n",
       "7                 0.07451  ...          28.14           110.60       897.0   \n",
       "8                 0.07389  ...          30.73           106.20       739.3   \n",
       "9                 0.08243  ...          40.68            97.65       711.4   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "5            0.1791             0.5249           0.5355                0.1741   \n",
       "6            0.1442             0.2576           0.3784                0.1932   \n",
       "7            0.1654             0.3682           0.2678                0.1556   \n",
       "8            0.1703             0.5401           0.5390                0.2060   \n",
       "9            0.1853             1.0580           1.1050                0.2210   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "5          0.3985                  0.12440       0  \n",
       "6          0.3063                  0.08368       0  \n",
       "7          0.3196                  0.11510       0  \n",
       "8          0.4378                  0.10720       0  \n",
       "9          0.4366                  0.20750       0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_frm.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a79fb729",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data,\n",
    "                                                    cancer.target,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f0ea9570",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "aa69bd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier :\n",
      "\n",
      "accuracy : 0.9649122807017544\n",
      "recall : 0.9827586206896551\n",
      "precistion : 0.9661016949152542\n",
      "f1 score : 0.9743589743589743\n"
     ]
    }
   ],
   "source": [
    "print('RandomForestClassifier :')\n",
    "print()\n",
    "metrics_eval(y_test, dt_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "70a876f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차검증 :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9646639471639471"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('교차검증 :')\n",
    "fold = KFold(n_splits=20)\n",
    "scoring = {\n",
    "    'accuracy' : make_scorer(accuracy_score),\n",
    "    'recall' : make_scorer(recall_score),\n",
    "    'precistion' : make_scorer(precision_score),\n",
    "    'f1' : make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "result = cross_validate(rf_model, X_train, y_train,\n",
    "                        cv = fold,\n",
    "                        scoring=scoring)\n",
    "result['test_recall'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2417d2",
   "metadata": {},
   "source": [
    "## 재현율을 높이기 위한 방법 : GridSearchCV를 이용한 파라미터 튜닝\n",
    "- n_estimators : tree의 갯수 의미\n",
    "- max_features : 최대 선택할 피처의 수를 의미\n",
    "- max_depth : 최대 선택할 트리의 깊이를 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "11b30142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=20, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [4, 6, 8], 'max_features': [6, 8, 15, 20],\n",
       "                         'n_estimators': [50, 100, 150, 200]},\n",
       "             scoring='recall')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {\n",
    "    'n_estimators' : [50, 100, 150, 200],\n",
    "    'max_features' : [6, 8, 15, 20], ## 무작위로 뽑음\n",
    "    'max_depth' : [4, 6, 8]\n",
    "}\n",
    "\n",
    "grid_search_model = GridSearchCV(rf_model,\n",
    "                                 param_grid = param,\n",
    "                                 cv = 20,\n",
    "                                 refit = True,\n",
    "                                 scoring = 'recall')\n",
    "grid_search_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9e13236f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.0716327 , 0.14171993, 0.21353503, 0.28254789, 0.07723602,\n",
       "        0.15337101, 0.22945303, 0.30620902, 0.09710181, 0.19312574,\n",
       "        0.29302424, 0.38794888, 0.11265268, 0.22365398, 0.33514849,\n",
       "        0.44580448, 0.0737669 , 0.14923189, 0.22186565, 0.29546068,\n",
       "        0.0806175 , 0.16107363, 0.24134492, 0.32168006, 0.10520165,\n",
       "        0.20639759, 0.30935024, 0.40849799, 0.11853753, 0.23994485,\n",
       "        0.35663067, 0.47537203, 0.07439611, 0.14828452, 0.22146246,\n",
       "        0.29527947, 0.08184739, 0.1614467 , 0.24100639, 0.32047322,\n",
       "        0.10349387, 0.20744942, 0.30872134, 0.41717523, 0.12035908,\n",
       "        0.24022903, 0.35734349, 0.47645775]),\n",
       " 'std_fit_time': array([0.00097061, 0.00076722, 0.0041682 , 0.00179765, 0.0006826 ,\n",
       "        0.00079268, 0.00083629, 0.001896  , 0.00081554, 0.0013972 ,\n",
       "        0.00364017, 0.0051382 , 0.00120503, 0.00592676, 0.00271437,\n",
       "        0.00372484, 0.00071479, 0.00433269, 0.00207629, 0.00560361,\n",
       "        0.00096602, 0.00298803, 0.00314113, 0.00843552, 0.00523395,\n",
       "        0.00303795, 0.0033554 , 0.00907858, 0.00185095, 0.00619443,\n",
       "        0.00479781, 0.00827285, 0.00055837, 0.00149382, 0.00139295,\n",
       "        0.00259938, 0.00157775, 0.00179349, 0.00235361, 0.00277854,\n",
       "        0.00229122, 0.00439911, 0.00413139, 0.01187201, 0.00206129,\n",
       "        0.00459726, 0.00450527, 0.0059849 ]),\n",
       " 'mean_score_time': array([0.00510503, 0.00900859, 0.01308018, 0.01706445, 0.00513015,\n",
       "        0.00910921, 0.01316381, 0.01716646, 0.00515649, 0.00930903,\n",
       "        0.01316277, 0.01728665, 0.00510434, 0.00915934, 0.01310835,\n",
       "        0.01720858, 0.00505469, 0.00916827, 0.01306185, 0.01711584,\n",
       "        0.00510596, 0.00931029, 0.01311396, 0.01706614, 0.00512881,\n",
       "        0.00915841, 0.01323512, 0.01711601, 0.00510837, 0.00925868,\n",
       "        0.01323515, 0.01709542, 0.0052034 , 0.00915868, 0.01308826,\n",
       "        0.01706454, 0.00525445, 0.00915838, 0.01310633, 0.01721671,\n",
       "        0.00510482, 0.00913391, 0.01317623, 0.01716491, 0.00520532,\n",
       "        0.00905863, 0.01310941, 0.01705567]),\n",
       " 'std_score_time': array([3.00564606e-04, 1.24999339e-06, 3.84309657e-04, 2.18744343e-04,\n",
       "        3.12737026e-04, 3.01262971e-04, 3.57601292e-04, 3.58330190e-04,\n",
       "        3.57441606e-04, 4.59341363e-04, 3.57194338e-04, 5.33226856e-04,\n",
       "        3.00238220e-04, 3.56016905e-04, 3.04119102e-04, 4.05777250e-04,\n",
       "        2.18138094e-04, 3.55819729e-04, 2.17951114e-04, 3.00193802e-04,\n",
       "        2.99912193e-04, 4.58320529e-04, 4.35649128e-04, 3.85104715e-04,\n",
       "        3.86029452e-04, 3.57478637e-04, 4.00360397e-04, 2.99447005e-04,\n",
       "        2.99457375e-04, 4.33010630e-04, 4.01091873e-04, 3.26991810e-04,\n",
       "        4.00138067e-04, 3.57827664e-04, 2.37574816e-04, 2.21823130e-04,\n",
       "        4.33049490e-04, 3.57552262e-04, 3.04942736e-04, 3.99864173e-04,\n",
       "        3.00554874e-04, 3.85332609e-04, 3.57770080e-04, 3.57692882e-04,\n",
       "        4.00378557e-04, 2.18152144e-04, 3.01138732e-04, 1.32030653e-04]),\n",
       " 'param_max_depth': masked_array(data=[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=[6, 6, 6, 6, 8, 8, 8, 8, 15, 15, 15, 15, 20, 20, 20, 20,\n",
       "                    6, 6, 6, 6, 8, 8, 8, 8, 15, 15, 15, 15, 20, 20, 20, 20,\n",
       "                    6, 6, 6, 6, 8, 8, 8, 8, 15, 15, 15, 15, 20, 20, 20, 20],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[50, 100, 150, 200, 50, 100, 150, 200, 50, 100, 150,\n",
       "                    200, 50, 100, 150, 200, 50, 100, 150, 200, 50, 100,\n",
       "                    150, 200, 50, 100, 150, 200, 50, 100, 150, 200, 50,\n",
       "                    100, 150, 200, 50, 100, 150, 200, 50, 100, 150, 200,\n",
       "                    50, 100, 150, 200],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 4, 'max_features': 6, 'n_estimators': 50},\n",
       "  {'max_depth': 4, 'max_features': 6, 'n_estimators': 100},\n",
       "  {'max_depth': 4, 'max_features': 6, 'n_estimators': 150},\n",
       "  {'max_depth': 4, 'max_features': 6, 'n_estimators': 200},\n",
       "  {'max_depth': 4, 'max_features': 8, 'n_estimators': 50},\n",
       "  {'max_depth': 4, 'max_features': 8, 'n_estimators': 100},\n",
       "  {'max_depth': 4, 'max_features': 8, 'n_estimators': 150},\n",
       "  {'max_depth': 4, 'max_features': 8, 'n_estimators': 200},\n",
       "  {'max_depth': 4, 'max_features': 15, 'n_estimators': 50},\n",
       "  {'max_depth': 4, 'max_features': 15, 'n_estimators': 100},\n",
       "  {'max_depth': 4, 'max_features': 15, 'n_estimators': 150},\n",
       "  {'max_depth': 4, 'max_features': 15, 'n_estimators': 200},\n",
       "  {'max_depth': 4, 'max_features': 20, 'n_estimators': 50},\n",
       "  {'max_depth': 4, 'max_features': 20, 'n_estimators': 100},\n",
       "  {'max_depth': 4, 'max_features': 20, 'n_estimators': 150},\n",
       "  {'max_depth': 4, 'max_features': 20, 'n_estimators': 200},\n",
       "  {'max_depth': 6, 'max_features': 6, 'n_estimators': 50},\n",
       "  {'max_depth': 6, 'max_features': 6, 'n_estimators': 100},\n",
       "  {'max_depth': 6, 'max_features': 6, 'n_estimators': 150},\n",
       "  {'max_depth': 6, 'max_features': 6, 'n_estimators': 200},\n",
       "  {'max_depth': 6, 'max_features': 8, 'n_estimators': 50},\n",
       "  {'max_depth': 6, 'max_features': 8, 'n_estimators': 100},\n",
       "  {'max_depth': 6, 'max_features': 8, 'n_estimators': 150},\n",
       "  {'max_depth': 6, 'max_features': 8, 'n_estimators': 200},\n",
       "  {'max_depth': 6, 'max_features': 15, 'n_estimators': 50},\n",
       "  {'max_depth': 6, 'max_features': 15, 'n_estimators': 100},\n",
       "  {'max_depth': 6, 'max_features': 15, 'n_estimators': 150},\n",
       "  {'max_depth': 6, 'max_features': 15, 'n_estimators': 200},\n",
       "  {'max_depth': 6, 'max_features': 20, 'n_estimators': 50},\n",
       "  {'max_depth': 6, 'max_features': 20, 'n_estimators': 100},\n",
       "  {'max_depth': 6, 'max_features': 20, 'n_estimators': 150},\n",
       "  {'max_depth': 6, 'max_features': 20, 'n_estimators': 200},\n",
       "  {'max_depth': 8, 'max_features': 6, 'n_estimators': 50},\n",
       "  {'max_depth': 8, 'max_features': 6, 'n_estimators': 100},\n",
       "  {'max_depth': 8, 'max_features': 6, 'n_estimators': 150},\n",
       "  {'max_depth': 8, 'max_features': 6, 'n_estimators': 200},\n",
       "  {'max_depth': 8, 'max_features': 8, 'n_estimators': 50},\n",
       "  {'max_depth': 8, 'max_features': 8, 'n_estimators': 100},\n",
       "  {'max_depth': 8, 'max_features': 8, 'n_estimators': 150},\n",
       "  {'max_depth': 8, 'max_features': 8, 'n_estimators': 200},\n",
       "  {'max_depth': 8, 'max_features': 15, 'n_estimators': 50},\n",
       "  {'max_depth': 8, 'max_features': 15, 'n_estimators': 100},\n",
       "  {'max_depth': 8, 'max_features': 15, 'n_estimators': 150},\n",
       "  {'max_depth': 8, 'max_features': 15, 'n_estimators': 200},\n",
       "  {'max_depth': 8, 'max_features': 20, 'n_estimators': 50},\n",
       "  {'max_depth': 8, 'max_features': 20, 'n_estimators': 100},\n",
       "  {'max_depth': 8, 'max_features': 20, 'n_estimators': 150},\n",
       "  {'max_depth': 8, 'max_features': 20, 'n_estimators': 200}],\n",
       " 'split0_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split1_test_score': array([0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 1.        , 0.91666667,\n",
       "        0.91666667, 0.91666667, 1.        , 1.        , 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        1.        , 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        1.        , 0.91666667, 0.91666667, 0.91666667, 1.        ,\n",
       "        1.        , 0.91666667, 0.91666667]),\n",
       " 'split2_test_score': array([0.91666667, 1.        , 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 1.        , 1.        , 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 1.        , 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 1.        ,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667]),\n",
       " 'split3_test_score': array([1.        , 1.        , 1.        , 1.        , 0.91666667,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.91666667, 1.        , 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.91666667, 1.        , 1.        , 1.        , 0.91666667,\n",
       "        0.91666667, 0.91666667, 1.        , 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.91666667, 1.        , 1.        ,\n",
       "        1.        , 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667]),\n",
       " 'split4_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split5_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split6_test_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.91666667, 1.        ,\n",
       "        1.        , 1.        , 0.91666667, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.91666667, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.91666667, 1.        , 1.        ,\n",
       "        0.91666667, 0.91666667, 1.        , 1.        , 1.        ,\n",
       "        0.91666667, 1.        , 1.        ]),\n",
       " 'split7_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split8_test_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.91666667, 1.        , 1.        , 1.        , 0.91666667,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.91666667,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.91666667,\n",
       "        1.        , 1.        , 1.        ]),\n",
       " 'split9_test_score': array([0.91666667, 0.91666667, 0.91666667, 0.91666667, 1.        ,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        1.        , 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 1.        ,\n",
       "        1.        , 1.        , 0.91666667, 1.        , 0.91666667,\n",
       "        0.91666667, 1.        , 0.91666667, 0.91666667, 0.91666667,\n",
       "        1.        , 1.        , 0.91666667, 0.91666667, 1.        ,\n",
       "        1.        , 1.        , 1.        ]),\n",
       " 'split10_test_score': array([0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 1.        , 0.91666667, 0.91666667, 1.        ,\n",
       "        1.        , 0.91666667, 0.91666667, 1.        , 0.91666667,\n",
       "        1.        , 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 1.        , 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 1.        , 0.91666667,\n",
       "        1.        , 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 1.        , 0.91666667, 1.        , 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667]),\n",
       " 'split11_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split12_test_score': array([0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.83333333, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667]),\n",
       " 'split13_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split14_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split15_test_score': array([0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        1.        , 0.91666667, 1.        , 0.91666667, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 1.        , 1.        , 1.        ,\n",
       "        0.91666667, 1.        , 1.        , 0.91666667, 0.91666667,\n",
       "        1.        , 1.        , 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 1.        , 0.91666667, 0.91666667, 0.91666667,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ]),\n",
       " 'split16_test_score': array([0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 1.        , 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667]),\n",
       " 'split17_test_score': array([1.        , 1.        , 1.        , 1.        , 0.91666667,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.91666667,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.91666667,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.91666667, 1.        ]),\n",
       " 'split18_test_score': array([1.        , 1.        , 1.        , 1.        , 0.91666667,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.91666667, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ]),\n",
       " 'split19_test_score': array([0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        1.        , 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 1.        , 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 1.        , 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        1.        , 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667, 0.91666667]),\n",
       " 'mean_test_score': array([0.96666667, 0.97083333, 0.96666667, 0.96666667, 0.95833333,\n",
       "        0.97083333, 0.97083333, 0.975     , 0.97083333, 0.97083333,\n",
       "        0.97083333, 0.97083333, 0.96666667, 0.97916667, 0.97083333,\n",
       "        0.975     , 0.975     , 0.96666667, 0.96666667, 0.96666667,\n",
       "        0.96666667, 0.96666667, 0.975     , 0.975     , 0.95833333,\n",
       "        0.9625    , 0.96666667, 0.97083333, 0.9625    , 0.9625    ,\n",
       "        0.975     , 0.97083333, 0.975     , 0.97083333, 0.97083333,\n",
       "        0.97083333, 0.97916667, 0.95833333, 0.97083333, 0.96666667,\n",
       "        0.97916667, 0.96666667, 0.96666667, 0.96666667, 0.97083333,\n",
       "        0.97083333, 0.96666667, 0.97083333]),\n",
       " 'std_test_score': array([0.04082483, 0.03974747, 0.04082483, 0.04082483, 0.04166667,\n",
       "        0.03974747, 0.03974747, 0.03818813, 0.03974747, 0.03974747,\n",
       "        0.03974747, 0.03974747, 0.04082483, 0.03608439, 0.03974747,\n",
       "        0.03818813, 0.03818813, 0.04859127, 0.04082483, 0.04082483,\n",
       "        0.04082483, 0.04082483, 0.03818813, 0.03818813, 0.04166667,\n",
       "        0.04145781, 0.04082483, 0.03974747, 0.04145781, 0.04145781,\n",
       "        0.03818813, 0.03974747, 0.03818813, 0.03974747, 0.03974747,\n",
       "        0.03974747, 0.03608439, 0.04166667, 0.03974747, 0.04082483,\n",
       "        0.03608439, 0.04082483, 0.04082483, 0.04082483, 0.03974747,\n",
       "        0.03974747, 0.04082483, 0.03974747]),\n",
       " 'rank_test_score': array([28, 11, 28, 28, 46, 11, 11,  4, 11, 11, 11, 11, 28,  1, 11,  4,  4,\n",
       "        28, 28, 28, 28, 28,  4,  4, 47, 44, 28, 11, 44, 43,  4, 11,  4, 11,\n",
       "        11, 11,  1, 47, 11, 28,  3, 28, 28, 28, 11, 11, 28, 11])}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "28ba65a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4, 'max_features': 20, 'n_estimators': 100}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "469b36ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9791666666666667"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "600b2c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_estimator = grid_search_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d858867b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9590643274853801\n",
      "recall : 0.9827586206896551\n",
      "precistion : 0.957983193277311\n",
      "f1 score : 0.9702127659574468\n"
     ]
    }
   ],
   "source": [
    "best_y_pred = re_estimator.predict(X_test)\n",
    "metrics_eval(y_test, best_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8952b2e2",
   "metadata": {},
   "source": [
    "### 정밀도(Precision)와 재현율(Recall)을 임의로 조절하는 모델을 생성해야 하는 경우\n",
    "- 분류 임계값이 낮을수록 positive를 예측할 확률이 높아져 재현율이 증가\n",
    "- predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3e8c1d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = [\n",
    "    [-1, -1, 2],\n",
    "    [2, 0, 0],\n",
    "    [0, 1.1, 1.2]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "91e88381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "holder = Binarizer(threshold = 1.1) # 1.1 보다 낮은건 0\n",
    "print(holder.fit_transform(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "1ac10fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_frm = pd.read_csv('./dataset/titanic_train.csv')\n",
    "titanic_frm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "dddd3bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target type : <class 'pandas.core.series.Series'>\n",
      "feature type : <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "titanic_target = titanic_frm['Survived']\n",
    "titanic_feature = titanic_frm.drop(['Survived'], axis=1)\n",
    "\n",
    "print('target type :', type(titanic_target))\n",
    "print('feature type :', type(titanic_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "386a79ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>label_items_Sex_female</th>\n",
       "      <th>label_items_Sex_male</th>\n",
       "      <th>label_items_mask_cabin_A</th>\n",
       "      <th>label_items_mask_cabin_B</th>\n",
       "      <th>label_items_mask_cabin_C</th>\n",
       "      <th>label_items_mask_cabin_D</th>\n",
       "      <th>label_items_mask_cabin_E</th>\n",
       "      <th>label_items_mask_cabin_F</th>\n",
       "      <th>label_items_mask_cabin_G</th>\n",
       "      <th>label_items_mask_cabin_N</th>\n",
       "      <th>label_items_mask_cabin_T</th>\n",
       "      <th>label_items_Embarked_C</th>\n",
       "      <th>label_items_Embarked_N</th>\n",
       "      <th>label_items_Embarked_Q</th>\n",
       "      <th>label_items_Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass   Age  SibSp  Parch     Fare  label_items_Sex_female  \\\n",
       "0         3  22.0      1      0   7.2500                       0   \n",
       "1         1  38.0      1      0  71.2833                       1   \n",
       "2         3  26.0      0      0   7.9250                       1   \n",
       "3         1  35.0      1      0  53.1000                       1   \n",
       "4         3  35.0      0      0   8.0500                       0   \n",
       "..      ...   ...    ...    ...      ...                     ...   \n",
       "886       2  27.0      0      0  13.0000                       0   \n",
       "887       1  19.0      0      0  30.0000                       1   \n",
       "888       3  30.0      1      2  23.4500                       1   \n",
       "889       1  26.0      0      0  30.0000                       0   \n",
       "890       3  32.0      0      0   7.7500                       0   \n",
       "\n",
       "     label_items_Sex_male  label_items_mask_cabin_A  label_items_mask_cabin_B  \\\n",
       "0                       1                         0                         0   \n",
       "1                       0                         0                         0   \n",
       "2                       0                         0                         0   \n",
       "3                       0                         0                         0   \n",
       "4                       1                         0                         0   \n",
       "..                    ...                       ...                       ...   \n",
       "886                     1                         0                         0   \n",
       "887                     0                         0                         1   \n",
       "888                     0                         0                         0   \n",
       "889                     1                         0                         0   \n",
       "890                     1                         0                         0   \n",
       "\n",
       "     label_items_mask_cabin_C  label_items_mask_cabin_D  \\\n",
       "0                           0                         0   \n",
       "1                           1                         0   \n",
       "2                           0                         0   \n",
       "3                           1                         0   \n",
       "4                           0                         0   \n",
       "..                        ...                       ...   \n",
       "886                         0                         0   \n",
       "887                         0                         0   \n",
       "888                         0                         0   \n",
       "889                         1                         0   \n",
       "890                         0                         0   \n",
       "\n",
       "     label_items_mask_cabin_E  label_items_mask_cabin_F  \\\n",
       "0                           0                         0   \n",
       "1                           0                         0   \n",
       "2                           0                         0   \n",
       "3                           0                         0   \n",
       "4                           0                         0   \n",
       "..                        ...                       ...   \n",
       "886                         0                         0   \n",
       "887                         0                         0   \n",
       "888                         0                         0   \n",
       "889                         0                         0   \n",
       "890                         0                         0   \n",
       "\n",
       "     label_items_mask_cabin_G  label_items_mask_cabin_N  \\\n",
       "0                           0                         1   \n",
       "1                           0                         0   \n",
       "2                           0                         1   \n",
       "3                           0                         0   \n",
       "4                           0                         1   \n",
       "..                        ...                       ...   \n",
       "886                         0                         1   \n",
       "887                         0                         0   \n",
       "888                         0                         1   \n",
       "889                         0                         0   \n",
       "890                         0                         1   \n",
       "\n",
       "     label_items_mask_cabin_T  label_items_Embarked_C  label_items_Embarked_N  \\\n",
       "0                           0                       0                       0   \n",
       "1                           0                       1                       0   \n",
       "2                           0                       0                       0   \n",
       "3                           0                       0                       0   \n",
       "4                           0                       0                       0   \n",
       "..                        ...                     ...                     ...   \n",
       "886                         0                       0                       0   \n",
       "887                         0                       0                       0   \n",
       "888                         0                       0                       0   \n",
       "889                         0                       1                       0   \n",
       "890                         0                       0                       0   \n",
       "\n",
       "     label_items_Embarked_Q  label_items_Embarked_S  \n",
       "0                         0                       1  \n",
       "1                         0                       0  \n",
       "2                         0                       1  \n",
       "3                         0                       1  \n",
       "4                         0                       1  \n",
       "..                      ...                     ...  \n",
       "886                       0                       1  \n",
       "887                       0                       1  \n",
       "888                       0                       1  \n",
       "889                       0                       0  \n",
       "890                       1                       0  \n",
       "\n",
       "[891 rows x 20 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "c5f88f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "886    0\n",
       "887    1\n",
       "888    0\n",
       "889    1\n",
       "890    0\n",
       "Name: Survived, Length: 891, dtype: int64"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "baa06ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습과 테스트 분리 :\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('학습과 테스트 분리 :')\n",
    "print()\n",
    "X_train, X_test, y_train, y_test = train_test_split(titanic_concat,\n",
    "                                                    titanic_target,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f0b46776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((712, 20), (179, 20), (712,), (179,))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape , y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "972fe00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train,y_train)\n",
    "y_pred = logistic_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7c59ef49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "확률예측 값 : predict_proba()\n",
      "type : <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print('확률예측 값 : predict_proba()')\n",
    "predict_proba_result =logistic_model.predict_proba(X_text)\n",
    "print('type :', type(logistic_model.predict_log_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ef6509ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5937156 , 0.4062844 ],\n",
       "       [0.92319651, 0.07680349],\n",
       "       [0.88408149, 0.11591851]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba_result[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a51a6fa1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 268 and the array at index 1 has size 179",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4604/521026560.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred_prob_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredict_proba_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 268 and the array at index 1 has size 179"
     ]
    }
   ],
   "source": [
    "pred_prob_concat = np.concatenate([predict_proba_result, y_pred.reshape(-1,1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "2b81786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_th = 0.3\n",
    "predict_proba_poitive = predict_proba_result[:, 1].reshape(-1,1)\n",
    "user_pred = Binarizer(threshold = user_th).fit_transform(predict_proba_poitive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "084ec5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8cc57b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default\n",
      "\n",
      "accuracy : 0.7821229050279329\n",
      "recall : 0.6933333333333334\n",
      "precistion : 0.7647058823529411\n",
      "f1 score : 0.7272727272727272\n",
      "\n",
      "user thre 0.3\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [179, 268]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4604/2968745202.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'user thre'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_th\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmetrics_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4604/843054125.py\u001b[0m in \u001b[0;36mmetrics_eval\u001b[1;34m(target, prediction)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmetrics_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy :'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'recall :'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'precistion :'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    320\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [179, 268]"
     ]
    }
   ],
   "source": [
    "print('default')\n",
    "print()\n",
    "metrics_eval(y_test, y_pred)\n",
    "print()\n",
    "print('user thre', user_th)\n",
    "print()\n",
    "metrics_eval(y_test, user_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c828d02",
   "metadata": {},
   "source": [
    "## trade-off 시각화\n",
    "- precision_recall_curve(실제값, 예측 확률 값) : 임계값 변화에 따른 평가지표를 반환\n",
    "- 반환값 : 정밀도, 재현율, 임계 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9ee7bac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "c58d2cdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [179, 268]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4604/637328041.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpredict_proba_poitive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_proba_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_recall_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_proba_poitive\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'precision type :'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'recall type :'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'th type :'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mprecision_recall_curve\u001b[1;34m(y_true, probas_pred, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m     \"\"\"\n\u001b[1;32m--> 811\u001b[1;33m     fps, tps, thresholds = _binary_clf_curve(y_true, probas_pred,\n\u001b[0m\u001b[0;32m    812\u001b[0m                                              \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m                                              sample_weight=sample_weight)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     \u001b[0my_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    320\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [179, 268]"
     ]
    }
   ],
   "source": [
    "predict_proba_poitive = predict_proba_result[:, 1]\n",
    "precision, recall, th = precision_recall_curve(y_test, predict_proba_poitive)\n",
    "print('precision type :', type(precision))\n",
    "print('recall type :', type(recall))\n",
    "print('th type :', type(th))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "ebcb25a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Precision must be int or format string, not '[:]'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m_float_precision_changed\u001b[1;34m(self, change)\u001b[0m\n\u001b[0;32m    650\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m                 \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '[:]'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4604/3159412368.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'precision'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'[:]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2349\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2350\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2351\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2352\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\decorator.py\u001b[0m in \u001b[0;36mfun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\basic.py\u001b[0m in \u001b[0;36mprecision\u001b[1;34m(self, s)\u001b[0m\n\u001b[0;32m    556\u001b[0m         \"\"\"\n\u001b[0;32m    557\u001b[0m         \u001b[0mptformatter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformatters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text/plain'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m         \u001b[0mptformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat_precision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mptformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\traitlets.py\u001b[0m in \u001b[0;36m__set__\u001b[1;34m(self, obj, value)\u001b[0m\n\u001b[0;32m    604\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTraitError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The \"%s\" trait is read-only.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\traitlets.py\u001b[0m in \u001b[0;36mset\u001b[1;34m(self, obj, value)\u001b[0m\n\u001b[0;32m    593\u001b[0m             \u001b[1;31m# we explicitly compare silent to True just in case the equality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m             \u001b[1;31m# comparison above returns something other than True/False\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m             \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_notify_trait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__set__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\traitlets.py\u001b[0m in \u001b[0;36m_notify_trait\u001b[1;34m(self, name, old_value, new_value)\u001b[0m\n\u001b[0;32m   1217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_notify_trait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1219\u001b[1;33m         self.notify_change(Bunch(\n\u001b[0m\u001b[0;32m   1220\u001b[0m             \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1221\u001b[0m             \u001b[0mold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mold_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\traitlets.py\u001b[0m in \u001b[0;36mnotify_change\u001b[1;34m(self, change)\u001b[0m\n\u001b[0;32m   1227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnotify_change\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchange\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1228\u001b[0m         \u001b[1;34m\"\"\"Notify observers of a change event\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1229\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_notify_observers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1231\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_notify_observers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\traitlets.py\u001b[0m in \u001b[0;36m_notify_observers\u001b[1;34m(self, event)\u001b[0m\n\u001b[0;32m   1264\u001b[0m                 \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1266\u001b[1;33m             \u001b[0mc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_add_notifiers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m_float_precision_changed\u001b[1;34m(self, change)\u001b[0m\n\u001b[0;32m    652\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Precision must be int or format string, not %r\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    655\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"int precision must be non-negative, not %r\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Precision must be int or format string, not '[:]'"
     ]
    }
   ],
   "source": [
    "precision[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "2f14e0ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'th' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4604/4144734053.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'--'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'precision'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'recall'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'th' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.plot(th, precision, linestyle='--', label='precision')\n",
    "plt.plot(th, recall, linestyle='-', label='recall')\n",
    "\n",
    "plt.xlabel('threshold ratio')\n",
    "plt.ylabel('precision and recall value')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb759043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
